{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c65b1a3c-3a6e-4001-8dcf-b2574bde2a34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install img2table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5437c52-b361-49ff-8d0b-65a64dcea437",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install pytesseract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddb9de1-c4bf-4ca7-afa2-3b6cff8ae25a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0657aac-5601-4e88-9691-c92d15e7a2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dec12f4-551d-45a8-b58c-95a81b76d0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1283297-7c22-458e-888f-d307347ecfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa2bd8f1-a366-4b90-96ab-7964fceea64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import numpy\n",
    "from PIL import Image\n",
    "import io\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pytesseract\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681658de-23e0-43e2-bc00-0c8064c3868c",
   "metadata": {},
   "source": [
    "## Image processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "077d93a4-f944-4edb-9ef1-c1cb8bcd224b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_img(path):\n",
    "    pdf = fitz.open(path)\n",
    "    counter = 1\n",
    "    pages = []\n",
    "    for i in range (len(pdf)):\n",
    "        page = pdf[i]\n",
    "        images = page.get_images()\n",
    "        for image in images:\n",
    "            base_img = pdf.extract_image(image[0])\n",
    "            image_data = base_img[\"image\"]\n",
    "            img = Image.open(io.BytesIO(image_data))\n",
    "            #extension = base_img[\"ext\"]\n",
    "            #img.save(open(f\"image{counter}.{extension}\", \"wb\"))\n",
    "            pages.append(img)\n",
    "            #counter += 1\n",
    "\n",
    "    return pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8139bfa-18f9-4ebf-9cf8-98fb56379791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(im_path):\n",
    "    dpi = 80\n",
    "    im_data = plt.imread(im_path)\n",
    "\n",
    "    height, width = im_data.shape[:2]\n",
    "\n",
    "    # What size does the figure need to be in inches to fit the image?\n",
    "    figsize = width / float(dpi), height / float(dpi)\n",
    "\n",
    "    # Create a figure of the right size with one axes that takes up the full figure\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.add_axes([0, 0, 1, 1])\n",
    "\n",
    "    # Hide spines, ticks, etc.\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Display the image.\n",
    "    ax.imshow(im_data, cmap='gray')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24b5e157-a51f-44fd-a3c5-4ddc967fc6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSkewAngle(cvImage) -> float:\n",
    "    # Prep image, copy, convert to gray scale, blur, and threshold\n",
    "    gray = cvImage.copy()\n",
    "    newImage = cvImage.copy()\n",
    "    blur = cv2.GaussianBlur(gray, (9, 9), 0)\n",
    "    thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "    # Apply dilate to merge text into meaningful lines/paragraphs.\n",
    "    # Use larger kernel on X axis to merge characters into single line, cancelling out any spaces.\n",
    "    # But use smaller kernel on Y axis to separate between different blocks of text\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (30, 5))\n",
    "    dilate = cv2.dilate(thresh, kernel, iterations=2)\n",
    "\n",
    "    # Find all contours\n",
    "    contours, hierarchy = cv2.findContours(dilate, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = sorted(contours, key = cv2.contourArea, reverse = True)\n",
    "    for c in contours[:1]:\n",
    "        rect = cv2.boundingRect(c)\n",
    "        x,y,w,h = rect\n",
    "        cv2.rectangle(newImage,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "\n",
    "    # Find largest contour and surround in min area box\n",
    "    largestContour = contours[0]\n",
    "    minAreaRect = cv2.minAreaRect(largestContour)\n",
    "    # Determine the angle. Convert it to the value that was originally used to obtain skewed image\n",
    "    angle = minAreaRect[-1]\n",
    "    if angle > 45:\n",
    "        angle = angle - 90\n",
    "    return -1.0 * angle\n",
    "# Rotate the image around its center\n",
    "def rotateImage(cvImage, angle: float):\n",
    "    newImage = cvImage.copy()\n",
    "    (h, w) = newImage.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    newImage = cv2.warpAffine(newImage, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "    return newImage\n",
    "\n",
    "# Deskew image\n",
    "def deskew(cvImage):\n",
    "    angle = getSkewAngle(cvImage)\n",
    "    return rotateImage(cvImage, -1.0 * angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21742ebf-41bd-4008-8e9a-5c3fc54af0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_removal(image):\n",
    "    import numpy as np\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    image = cv2.dilate(image, kernel, iterations=1)\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    image = cv2.erode(image, kernel, iterations=1)\n",
    "    image = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n",
    "    image = cv2.medianBlur(image, 3)\n",
    "    return (image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e23fd775-4d42-4982-ac25-c212561f08ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tables(image):\n",
    "    BLUR_KERNEL_SIZE = (17, 17)\n",
    "    STD_DEV_X_DIRECTION = 0\n",
    "    STD_DEV_Y_DIRECTION = 0\n",
    "    blurred = cv2.GaussianBlur(image, BLUR_KERNEL_SIZE, STD_DEV_X_DIRECTION, STD_DEV_Y_DIRECTION)\n",
    "    MAX_COLOR_VAL = 255\n",
    "    BLOCK_SIZE = 15\n",
    "    SUBTRACT_FROM_MEAN = -2\n",
    "    \n",
    "    img_bin = cv2.adaptiveThreshold(\n",
    "        ~blurred,\n",
    "        MAX_COLOR_VAL,\n",
    "        cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "        cv2.THRESH_BINARY,\n",
    "        BLOCK_SIZE,\n",
    "        SUBTRACT_FROM_MEAN,\n",
    "    )\n",
    "    vertical = horizontal = img_bin.copy()\n",
    "    SCALE = 5\n",
    "    image_width, image_height = horizontal.shape\n",
    "    horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (int(image_width / SCALE), 1))\n",
    "    horizontally_opened = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, horizontal_kernel)\n",
    "    vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, int(image_height / SCALE)))\n",
    "    vertically_opened = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, vertical_kernel)\n",
    "    \n",
    "    horizontally_dilated = cv2.dilate(horizontally_opened, cv2.getStructuringElement(cv2.MORPH_RECT, (40, 1)))\n",
    "    vertically_dilated = cv2.dilate(vertically_opened, cv2.getStructuringElement(cv2.MORPH_RECT, (1, 60)))\n",
    "    \n",
    "    mask = horizontally_dilated + vertically_dilated\n",
    "    contours, heirarchy = cv2.findContours(\n",
    "        mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE,\n",
    "    )\n",
    "\n",
    "    MIN_TABLE_AREA = 1e5\n",
    "    contours = [c for c in contours if cv2.contourArea(c) > MIN_TABLE_AREA]\n",
    "    perimeter_lengths = [cv2.arcLength(c, True) for c in contours]\n",
    "    epsilons = [0.1 * p for p in perimeter_lengths]\n",
    "    approx_polys = [cv2.approxPolyDP(c, e, True) for c, e in zip(contours, epsilons)]\n",
    "    bounding_rects = [cv2.boundingRect(a) for a in approx_polys]\n",
    "\n",
    "    # The link where a lot of this code was borrowed from recommends an\n",
    "    # additional step to check the number of \"joints\" inside this bounding rectangle.\n",
    "    # A table should have a lot of intersections. We might have a rectangular image\n",
    "    # here though which would only have 4 intersections, 1 at each corner.\n",
    "    # Leaving that step as a future TODO if it is ever necessary.\n",
    "    images = [image[y:y+h, x:x+w] for x, y, w, h in bounding_rects]\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "050b9458-2fd5-4f54-9254-bf2a5f2f602b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_assembler(image):\n",
    "    image = np.array(image)\n",
    "    thresh, thresholdedPage = cv2.threshold(image, 200, 255, cv2.THRESH_BINARY)\n",
    "    image = thresholdedPage\n",
    "    image = noise_removal(image)\n",
    "    image = deskew(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134382fc-6003-4a3b-a1a2-bda55c177547",
   "metadata": {},
   "source": [
    "## Image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecaa385f-790f-43af-8740-b70c2f442a6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pdfs = []\n",
    "\n",
    "for filename in os.listdir(\"Probe\"):\n",
    "    pdfs.append(f\"Probe/{filename}\")\n",
    "\n",
    "for pdf in pdfs[:1]: \n",
    "    pages = pdf_to_img(pdf)\n",
    "    text = []\n",
    "    \n",
    "    for i in range(len(pages)):\n",
    "        pages[i] = np.array(pages[i])\n",
    "        thresh, thresholdedPage = cv2.threshold(pages[i], 200, 255, cv2.THRESH_BINARY)\n",
    "        pages[i] = thresholdedPage\n",
    "        pages[i] = noise_removal(pages[i])\n",
    "        pages[i] = deskew(pages[i])\n",
    "        text.append(pytesseract.image_to_string(Image.fromarray(pages[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ce3aa0-259f-4d68-847d-318e2daff627",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "proba1 = pdf_to_img(\"proba1.pdf\")\n",
    "\n",
    "text = pytesseract.image_to_string(proba1[0])\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1214f1-7bc5-419f-9b41-fdd8ba606aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = pytesseract.image_to_string(preprocessing_assembler(proba1[0]))\n",
    "print(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e901fc3a-807d-438c-a804-37fa4ad0f600",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adresa $au-zona | 7 ‘<: -|\\dob&ndirii Suprafata parte| dobandire’\"{ =\" Titularul\n",
      "PODU DAMBOVIJEI PITEA NICULINA 3/6\n",
      "JUD. ARGES CASA DE ~ PITEA NICOLETA 1/6\n",
      "LOCUIT 2006 194 mp 1/6 | SUCCESIUNE PITEA ION 1/6\n",
      "LAMBESCU DANIELAI/6\n",
      "PODU DAMBOVITEI PITEA NICULINA 3/6\n",
      "JUD. ARGES PITEA NICOLETA 1/6\n",
      "ANEXA 2006 40 mp 1/46 | SUCCESIUNE PITEA ION 1/6\n",
      "LAMBESCU DANIELA1/6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text2 = pytesseract.image_to_string(preprocessing_assembler(Image.open(\"example-table.png\")), config=\"--psm 6\")\n",
    "print(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1a3640ff-e688-469e-a0ab-1429941807a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba5 = pdf_to_img(\"proba1.pdf\")\n",
    "\n",
    "page = np.array(proba5[0])   # n-a gasit primul tabel, l-a dat direct pe al doilea\n",
    "\n",
    "page = find_tables(preprocessing_assembler(page))[0]                 #da tabelele de jos in sus\n",
    "\n",
    "cv2.imwrite(\"example-table.png\", page)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928656fc-002d-445d-8429-587ed66cd6ff",
   "metadata": {},
   "source": [
    "## Experimental:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b7f728a0-0a9b-453f-8672-9053dfea8ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from pytesseract import Output\n",
    "from tabulate import tabulate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d18b45f6-0fd3-4d91-b63f-00dbb97fb463",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "args[\"min_conf\"] = 2\n",
    "args[\"min_size\"] = 2\n",
    "args[\"dist_thresh\"] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d3afe9c8-a47a-4b68-9cd6-0ecf0bde5499",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'table' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[96], line 83\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m sortedIdxs:\n\u001b[0;32m     80\u001b[0m \t\u001b[38;5;66;03m# extract the text bounding box coordinates and draw the\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \t\u001b[38;5;66;03m# bounding box surrounding the current element\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \t(x, y, w, h) \u001b[38;5;241m=\u001b[39m coords[i]\n\u001b[1;32m---> 83\u001b[0m \tcv2\u001b[38;5;241m.\u001b[39mrectangle(\u001b[43mtable\u001b[49m, (x, y), (x \u001b[38;5;241m+\u001b[39m w, y \u001b[38;5;241m+\u001b[39m h), color, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# extract the OCR'd text for the current column, then construct\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# a data frame for the data where the first entry in our column\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# serves as the header\u001b[39;00m\n\u001b[0;32m     87\u001b[0m cols \u001b[38;5;241m=\u001b[39m [ocrText[i]\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m sortedIdxs]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'table' is not defined"
     ]
    }
   ],
   "source": [
    "# set the PSM mode to detect sparse text, and then localize text in\n",
    "# the table\n",
    "options = \"--psm 6\"\n",
    "results = pytesseract.image_to_data(\n",
    "\tpreprocessing_assembler(Image.open(\"example-table.png\")),\n",
    "\tconfig=options,\n",
    "\toutput_type=Output.DICT)\n",
    "# initialize a list to store the (x, y)-coordinates of the detected\n",
    "# text along with the OCR'd text itself\n",
    "coords = []\n",
    "ocrText = []\n",
    "\n",
    "# loop over each of the individual text localizations\n",
    "for i in range(0, len(results[\"text\"])):\n",
    "\t# extract the bounding box coordinates of the text region from\n",
    "\t# the current result\n",
    "\tx = results[\"left\"][i]\n",
    "\ty = results[\"top\"][i]\n",
    "\tw = results[\"width\"][i]\n",
    "\th = results[\"height\"][i]\n",
    "\t# extract the OCR text itself along with the confidence of the\n",
    "\t# text localization\n",
    "\ttext = results[\"text\"][i]\n",
    "\tconf = int(results[\"conf\"][i])\n",
    "\t# filter out weak confidence text localizations\n",
    "\tif conf > args[\"min_conf\"]:\n",
    "\t\t# update our text bounding box coordinates and OCR'd text,\n",
    "\t\t# respectively\n",
    "\t\tcoords.append((x, y, w, h))\n",
    "\t\tocrText.append(text)\n",
    "\n",
    "\n",
    "# extract all x-coordinates from the text bounding boxes, setting the\n",
    "# y-coordinate value to zero\n",
    "xCoords = [(c[0], 0) for c in coords]\n",
    "# apply hierarchical agglomerative clustering to the coordinates\n",
    "clustering = AgglomerativeClustering(\n",
    "\tn_clusters=None,\n",
    "\tmetric =\"manhattan\",\n",
    "\tlinkage=\"complete\",\n",
    "\tdistance_threshold=args[\"dist_thresh\"])\n",
    "clustering.fit(xCoords)\n",
    "# initialize our list of sorted clusters\n",
    "sortedClusters = []\n",
    "\n",
    "\n",
    "# loop over all clusters\n",
    "for l in np.unique(clustering.labels_):\n",
    "\t# extract the indexes for the coordinates belonging to the\n",
    "\t# current cluster\n",
    "\tidxs = np.where(clustering.labels_ == l)[0]\n",
    "\t# verify that the cluster is sufficiently large\n",
    "\tif len(idxs) > args[\"min_size\"]:\n",
    "\t\t# compute the average x-coordinate value of the cluster and\n",
    "\t\t# update our clusters list with the current label and the\n",
    "\t\t# average x-coordinate\n",
    "\t\tavg = np.average([coords[i][0] for i in idxs])\n",
    "\t\tsortedClusters.append((l, avg))\n",
    "# sort the clusters by their average x-coordinate and initialize our\n",
    "# data frame\n",
    "sortedClusters.sort(key=lambda x: x[1])\n",
    "df = pd.DataFrame()\n",
    "\n",
    "\n",
    "# loop over the clusters again, this time in sorted order\n",
    "for (l, _) in sortedClusters:\n",
    "\t# extract the indexes for the coordinates belonging to the\n",
    "\t# current cluster\n",
    "\tidxs = np.where(clustering.labels_ == l)[0]\n",
    "\t# extract the y-coordinates from the elements in the current\n",
    "\t# cluster, then sort them from top-to-bottom\n",
    "\tyCoords = [coords[i][1] for i in idxs]\n",
    "\tsortedIdxs = idxs[np.argsort(yCoords)]\n",
    "\t# generate a random color for the cluster\n",
    "\tcolor = np.random.randint(0, 255, size=(3,), dtype=\"int\")\n",
    "\tcolor = [int(c) for c in color]\n",
    "\n",
    "\t# loop over the sorted indexes\n",
    "\tfor i in sortedIdxs:\n",
    "\t\t# extract the text bounding box coordinates and draw the\n",
    "\t\t# bounding box surrounding the current element\n",
    "\t\t(x, y, w, h) = coords[i]\n",
    "\t\tcv2.rectangle(table, (x, y), (x + w, y + h), color, 2)\n",
    "\t# extract the OCR'd text for the current column, then construct\n",
    "\t# a data frame for the data where the first entry in our column\n",
    "\t# serves as the header\n",
    "\tcols = [ocrText[i].strip() for i in sortedIdxs]\n",
    "\tcurrentDF = pd.DataFrame({cols[0]: cols[1:]})\n",
    "\t# concatenate *original* data frame with the *current* data\n",
    "\t# frame (we do this to handle columns that may have a varying\n",
    "\t# number of rows)\n",
    "\tdf = pd.concat([df, currentDF], axis=1)\n",
    "\n",
    "print(\"[INFO] saving CSV file to disk...\")\n",
    "df.to_csv(args[\"output\"], index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93473982-bb3e-4149-a42b-e2c64085fc90",
   "metadata": {},
   "source": [
    "## Experiment 2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "966550bd-7632-4a9d-a5f8-47501206e50f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'img2table.tables.image'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m doc \u001b[38;5;241m=\u001b[39m Image(src\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample-table.png\u001b[39m\u001b[38;5;124m\"\u001b[39m, detect_rotation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m ocr \u001b[38;5;241m=\u001b[39m TesseractOCR(n_threads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meng\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m extracted_tables \u001b[38;5;241m=\u001b[39m \u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_tables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mocr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mocr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mimplicit_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mborderless_tables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mmin_confidence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Result of table identification\u001b[39;00m\n\u001b[0;32m     14\u001b[0m img_tables\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\img2table\\document\\image.py:46\u001b[0m, in \u001b[0;36mImage.extract_tables\u001b[1;34m(self, ocr, implicit_rows, borderless_tables, min_confidence)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_tables\u001b[39m(\u001b[38;5;28mself\u001b[39m, ocr: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOCRInstance\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, implicit_rows: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, borderless_tables: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     37\u001b[0m                    min_confidence: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[ExtractedTable]:\n\u001b[0;32m     38\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m    Extract tables from document\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03m    :param ocr: OCRInstance object used to extract table content\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;124;03m    :return: list of extracted tables\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m     extracted_tables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mImage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_tables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mocr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mocr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m                                                         \u001b[49m\u001b[43mimplicit_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimplicit_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m                                                         \u001b[49m\u001b[43mborderless_tables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mborderless_tables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m                                                         \u001b[49m\u001b[43mmin_confidence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_confidence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m extracted_tables\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\img2table\\document\\base\\__init__.py:125\u001b[0m, in \u001b[0;36mDocument.extract_tables\u001b[1;34m(self, ocr, implicit_rows, borderless_tables, min_confidence)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03mExtract tables from document\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;124;03m:param ocr: OCRInstance object used to extract table content\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;124;03m:return: dictionary with page number as key and list of extracted tables as values\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# Extract tables from document\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimg2table\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtables\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TableImage\n\u001b[0;32m    126\u001b[0m tables \u001b[38;5;241m=\u001b[39m {idx: TableImage(img\u001b[38;5;241m=\u001b[39mimg,\n\u001b[0;32m    127\u001b[0m                           min_confidence\u001b[38;5;241m=\u001b[39mmin_confidence)\u001b[38;5;241m.\u001b[39mextract_tables(implicit_rows\u001b[38;5;241m=\u001b[39mimplicit_rows,\n\u001b[0;32m    128\u001b[0m                                                                         borderless_tables\u001b[38;5;241m=\u001b[39mborderless_tables)\n\u001b[0;32m    129\u001b[0m           \u001b[38;5;28;01mfor\u001b[39;00m idx, img \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimages)}\n\u001b[0;32m    131\u001b[0m \u001b[38;5;66;03m# Update table content with OCR if possible\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'img2table.tables.image'"
     ]
    }
   ],
   "source": [
    "from img2table.document import Image\n",
    "from img2table.ocr import TesseractOCR\n",
    "\n",
    "# Instantiation of the image\n",
    "doc = Image(src=\"example-table.png\", detect_rotation=False)\n",
    "ocr = TesseractOCR(n_threads=1, lang=\"eng\")\n",
    "\n",
    "extracted_tables = doc.extract_tables(ocr=ocr,\n",
    "                                      implicit_rows=False,\n",
    "                                      borderless_tables=False,\n",
    "                                      min_confidence=50)\n",
    "\n",
    "# Result of table identification\n",
    "img_tables\n",
    "\n",
    "[ExtractedTable(title=None, bbox=(10, 8, 745, 314),shape=(6, 3)),\n",
    " ExtractedTable(title=None, bbox=(936, 9, 1129, 111),shape=(2, 2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e76624c-a1e6-42fe-b05f-1ec561dcd6d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
